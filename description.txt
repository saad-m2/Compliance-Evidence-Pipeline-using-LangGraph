â€œCompliance Evidence Pipeline using LangGraphâ€

ğŸ¯ The Core Idea

You build a small, production-style AI pipeline that:

Takes a company website URL

Uses Playwright to capture evidence (HTML + screenshot)

Uses an LLM (abstracted like Bedrock) to extract structured compliance information

Validates output using a strict Pydantic schema

Retries extraction if validation fails

Generates a short structured report

Logs every step for auditability

This mimics what companies in regulated AI environments actually build.

ğŸ§  The Philosophy Behind It

This is not about scraping.

Itâ€™s about demonstrating:

Controlled AI workflows

Graph-based orchestration

Output validation

Retry logic

Audit trails

Production thinking

Youâ€™re simulating:

â€œAI system for regulated industries that must be reliable and auditable.â€

That aligns perfectly with:

KRITIS

Blueprint-first approach

Logging/Audit trails

Multi-agent workflows

ğŸ— High-Level Architecture

Graph flow:

[Start]
   â†“
[Collect Evidence via Playwright]
   â†“
[Extract Structured Data via LLM]
   â†“
[Validate with Pydantic]
   â†“
(If invalid and retry_count < 1)
      â†º Back to Extract
   â†“
[Generate Structured Report]
   â†“
[Write Audit Log]
   â†“
[End]


This is a true graph:

Conditional edge (retry)

Stateful transitions

Clear node responsibilities

ğŸ§± The State Object

Your graph has shared state:

{
  "url": str,
  "html": str | None,
  "screenshot_path": str | None,
  "extracted_data": dict | None,
  "validated": bool,
  "retry_count": int,
  "report": str | None
}


Every node:

Reads from state

Writes to state

Emits audit log

ğŸ•µï¸ Node 1 â€” Evidence Collector (Playwright)

What it does:

Opens URL

Waits for network idle

Saves:

raw.html

screenshot.png

Why this matters:

Deterministic evidence capture

Reproducibility

Audit trail

Compliance mindset

In interview language:

â€œThe evidence node ensures deterministic capture of webpage artifacts for traceability.â€

ğŸ¤– Node 2 â€” LLM Extraction (Bedrock-style abstraction)

You define a schema:

class ComplianceInfo(BaseModel):
    company_name: str
    contact_email: str | None
    mentions_iso27001: bool
    mentions_soc2: bool
    privacy_policy_present: bool


Prompt:

Extract the following fields from the HTML.
Return valid JSON only. No explanation.

Then:

Parse

Validate

If it fails â†’ retry once with corrective prompt.

ğŸ” Why Retry Is Important

LLMs:

Sometimes return invalid JSON

Sometimes miss fields

By adding retry logic:

You demonstrate:

You understand LLM unreliability

You design defensively

You donâ€™t blindly trust AI output

Thatâ€™s huge for regulated industries.

ğŸ“ Node 3 â€” Report Generator

Generates something structured:

Compliance Evidence Report
--------------------------
Company: X
ISO 27001 Mentioned: Yes
SOC2 Mentioned: No
Privacy Policy Present: Yes

Evidence Files:
- html: evidence/raw.html
- screenshot: evidence/screenshot.png


Clean and boring = good.

ğŸ“š Audit Logging

Every node logs something like:

{
  "timestamp": "...",
  "node": "extract",
  "status": "success",
  "retry_count": 0,
  "input_hash": "...",
  "output_hash": "..."
}


In real production:

This would go to DynamoDB

Or CloudWatch

Or S3 for full payloads

In your project:

Write to JSON file